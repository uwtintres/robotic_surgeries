{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TOPSIS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMm/rhAy+ZPevFo9aFSH4wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwtintres/robotic_surgeries/blob/main/TOPSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffDMBEtRdKKv"
      },
      "source": [
        "Project is the work of Alina Saduova, CSS graduate student at UWT,  Spring'21. \n",
        "This notebook is used for the TOPSIS algorithm with custom weights. The processing is done according to the next steps:\n",
        "\n",
        "1. Load .csv file with columns as attributes and rows as alternatives. \n",
        "2. Provide the array of weights as an input to the processing function. Also, the criteria types should be provided as the array, where the False value should be used in the weights of attributes with cost criteria (minimum value of the attribute is preferred), while for the attribute with benefit criteria (max value is preferred) True value should be provided. \n",
        "3. Processing of the input file is done on this step according to the weights provided on step 2.\n",
        "4. Visualizing the results.\n",
        "\n",
        "The following code is used for the TOPSIS experiment with custom weights. Each step of the experiment is printed for better understanding and the visualization chart for the rankings is porivded afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEr-G25MeMZ0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Topsis():\n",
        "    evaluation_matrix = np.array([])  # Matrix\n",
        "    weighted_normalized = np.array([])  # Weight matrix\n",
        "    normalized_decision = np.array([])  # Normalisation matrix\n",
        "    M = 0  # Number of rows\n",
        "    N = 0  # Number of columns\n",
        "\n",
        "    '''\n",
        "\tCreate an evaluation matrix consisting of m alternatives and n criteria.\n",
        "\t  '''\n",
        "\n",
        "    def __init__(self, evaluation_matrix, weight_matrix, criteria):\n",
        "        # MÃ—N matrix\n",
        "        self.evaluation_matrix = np.array(evaluation_matrix, dtype=\"float\")\n",
        "\n",
        "        # M alternatives (options)\n",
        "        self.row_size = len(self.evaluation_matrix)\n",
        "\n",
        "        # N attributes/criteria\n",
        "        self.column_size = len(self.evaluation_matrix[0])\n",
        "\n",
        "        # N size weight matrix\n",
        "        self.weight_matrix = np.array(weight_matrix, dtype=\"float\")\n",
        "        self.weight_matrix = self.weight_matrix/sum(self.weight_matrix)\n",
        "        self.criteria = np.array(criteria, dtype=\"float\")\n",
        "\n",
        "    '''\n",
        "\t# Step 2\n",
        "\tThe matrix  is then normalised.\n",
        "\t'''\n",
        "\n",
        "    def step_2(self):\n",
        "        # normalized scores\n",
        "        self.normalized_decision = np.copy(self.evaluation_matrix)\n",
        "        sqrd_sum = np.zeros(self.column_size)\n",
        "        for i in range(self.row_size):\n",
        "            for j in range(self.column_size):\n",
        "                sqrd_sum[j] += self.evaluation_matrix[i, j]**2\n",
        "        for i in range(self.row_size):\n",
        "            for j in range(self.column_size):\n",
        "                self.normalized_decision[i,\n",
        "                                         j] = self.evaluation_matrix[i, j]/(sqrd_sum[j]**0.5)\n",
        "\n",
        "    '''\n",
        "\t# Step 3\n",
        "\tCalculate the weighted normalised decision matrix\n",
        "\t'''\n",
        "\n",
        "    def step_3(self):\n",
        "        from pdb import set_trace\n",
        "        self.weighted_normalized = np.copy(self.normalized_decision)\n",
        "        for i in range(self.row_size):\n",
        "            for j in range(self.column_size):\n",
        "                self.weighted_normalized[i, j] *= self.weight_matrix[j]\n",
        "\n",
        "    '''\n",
        "\t# Step 4\n",
        "\tDetermine the ideal worst alternative and the ideal best alternative:\n",
        "\t'''\n",
        "\n",
        "    def step_4(self):\n",
        "        self.worst_alternatives = np.zeros(self.column_size)\n",
        "        self.best_alternatives = np.zeros(self.column_size)\n",
        "        for i in range(self.column_size):\n",
        "            if self.criteria[i]:\n",
        "                self.worst_alternatives[i] = min(\n",
        "                    self.weighted_normalized[:, i])\n",
        "                self.best_alternatives[i] = max(self.weighted_normalized[:, i])\n",
        "            else:\n",
        "                self.worst_alternatives[i] = max(\n",
        "                    self.weighted_normalized[:, i])\n",
        "                self.best_alternatives[i] = min(self.weighted_normalized[:, i])\n",
        "\n",
        "    '''\n",
        "\t# Step 5\n",
        "\tCalculate the L2-distance between the target alternative with the ideal worst \n",
        "  value and the ideal best value.\n",
        "\t'''\n",
        "\n",
        "    def step_5(self):\n",
        "        self.worst_distance = np.zeros(self.row_size)\n",
        "        self.best_distance = np.zeros(self.row_size)\n",
        "\n",
        "        self.worst_distance_mat = np.copy(self.weighted_normalized)\n",
        "        self.best_distance_mat = np.copy(self.weighted_normalized)\n",
        "\n",
        "        for i in range(self.row_size):\n",
        "            for j in range(self.column_size):\n",
        "                self.worst_distance_mat[i][j] = (self.weighted_normalized[i][j]-self.worst_alternatives[j])**2\n",
        "                self.best_distance_mat[i][j] = (self.weighted_normalized[i][j]-self.best_alternatives[j])**2\n",
        "                \n",
        "                self.worst_distance[i] += self.worst_distance_mat[i][j]\n",
        "                self.best_distance[i] += self.best_distance_mat[i][j]\n",
        "\n",
        "        for i in range(self.row_size):\n",
        "            self.worst_distance[i] = self.worst_distance[i]**0.5\n",
        "            self.best_distance[i] = self.best_distance[i]**0.5\n",
        "\n",
        "    '''\n",
        "\t# Step 6\n",
        "\tCalculate the preformance score\n",
        "\t'''\n",
        "\n",
        "    def step_6(self):\n",
        "        np.seterr(all='ignore')\n",
        "        self.preformance_score = np.zeros(self.row_size)\n",
        "\n",
        "        for i in range(self.row_size):\n",
        "            # calculate the similarity to the worst condition\n",
        "            self.preformance_score[i] = self.worst_distance[i] / \\\n",
        "                (self.worst_distance[i]+self.best_distance[i])\n",
        "    \n",
        "    def ranking(self, data):\n",
        "        return [i+1 for i in np.argsort(-1*data)]\n",
        "\n",
        "    def rank_to_preformance_score(self):\n",
        "        return self.ranking(self.preformance_score)\n",
        "\n",
        "    def visualization(self, ranking):\n",
        "        #ax = fig.add_axes([0,0,1,1])\n",
        "        axes = []\n",
        "        for i, rank in enumerate(ranking):\n",
        "          axes.append(((rank), (i + 1)))\n",
        "        axes.sort(key=lambda x: x[0])\n",
        "        x_axis,y_axis = ['A' + str(val[0]) for val in axes],[val[1] for val in axes]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ax = pd.Series(y_axis).plot(kind='bar')\n",
        "        ax.set_xticklabels(x_axis)\n",
        "\n",
        "        rects = ax.patches\n",
        "        for rect, label in zip(rects, y_axis):\n",
        "            height = rect.get_height()\n",
        "            ax.text(rect.get_x() + rect.get_width()/2, height, label, ha='center', va='bottom')\n",
        "        ax.bar(x_axis,y_axis)\n",
        "\n",
        "    def calc(self):\n",
        "        print(\"Step 1\\n\", self.evaluation_matrix, end=\"\\n\\n\")\n",
        "        self.step_2()\n",
        "        print(\"Step 2\\n\", self.normalized_decision, end=\"\\n\\n\")\n",
        "        self.step_3()\n",
        "        print(\"Step 3\\n\", self.weighted_normalized, end=\"\\n\\n\")\n",
        "        self.step_4()\n",
        "        print(\"Step 4\\n\", self.worst_alternatives,\n",
        "              self.best_alternatives, end=\"\\n\\n\")\n",
        "        self.step_5()\n",
        "        print(\"Step 5\\n\", self.worst_distance, self.best_distance, end=\"\\n\\n\")\n",
        "        self.step_6()\n",
        "        print(\"Step 6\\n\", self.preformance_score, end=\"\\n\\n\")\n",
        "        "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGFH3LODSlYd"
      },
      "source": [
        "The driver code for testing is presented below. The execution plan is as follows:\n",
        "  1. Read the excel file, where the file name and sheet_name should be provided to specify which case user wants to test. \n",
        "  2. Read the excel file to store the weights and criteria values.\n",
        "  3. Create Topsis instance with the read values\n",
        "  4. Calculate the rankings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDZ2YsUQiivO",
        "outputId": "8590e83e-bf82-4dd6-e553-be9709bb0deb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "xl = pd.read_excel(\"TOPSIS with custom weights.xlsx\", sheet_name=\"Beginning\", \n",
        "                   usecols=range(1, len(xl.columns)+1))\n",
        "\n",
        "# initializing input matrix, weights, criterias\n",
        "input_matrix = xl.tail(n=len(xl.index) - 2).values.tolist()\n",
        "weights = xl.loc[0].values\n",
        "criterias = xl.head(n=0).columns.values\n",
        "new_criterias = []\n",
        "for criteria in criterias:\n",
        "  # if the attribute is non beneficiary, meaning min value is better -> False, \n",
        "  # otherwise, the criteria is True\n",
        "  new_criterias.append(False if criteria[0] == 'N' else True)\n",
        "print('input matrix: ', input_matrix)\n",
        "print('weights: ', weights)\n",
        "print('criterias: ', new_criterias)\n",
        "# creating Topsis instance with the values above\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input matrix:  [[21, 300, 90, 60], [45, 800, 74, 30], [64, 700, 12, 90], [86, 1000, 36, 10], [75, 100, 24, 5], [34, 1200, 47, 23], [56, 400, 55, 67], [90, 350, 67, 84], [60, 580, 74, 75], [70, 460, 86, 98], [80, 220, 98, 46], [10, 900, 40, 15]]\n",
            "weights:  [0.6 0.1 0.1 0.2]\n",
            "criterias:  [False, False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2mZYgkqNisQI",
        "outputId": "13c2189c-6bc6-4284-a8a0-3c3990c19157"
      },
      "source": [
        "t = Topsis(input_matrix, weights, new_criterias)\n",
        "\n",
        "# calculating the ranking\n",
        "t.calc()\n",
        "\n",
        "ranks = t.rank_to_preformance_score()\n",
        "\n",
        "print(\"Visualization graph:\")\n",
        "t.visualization(ranks)  "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            " [[  21.  300.   90.   60.]\n",
            " [  45.  800.   74.   30.]\n",
            " [  64.  700.   12.   90.]\n",
            " [  86. 1000.   36.   10.]\n",
            " [  75.  100.   24.    5.]\n",
            " [  34. 1200.   47.   23.]\n",
            " [  56.  400.   55.   67.]\n",
            " [  90.  350.   67.   84.]\n",
            " [  60.  580.   74.   75.]\n",
            " [  70.  460.   86.   98.]\n",
            " [  80.  220.   98.   46.]\n",
            " [  10.  900.   40.   15.]]\n",
            "\n",
            "Step 2\n",
            " [[0.09689155 0.12959356 0.40496603 0.29149234]\n",
            " [0.20762475 0.34558283 0.33297207 0.14574617]\n",
            " [0.29528853 0.30238498 0.05399547 0.43723851]\n",
            " [0.39679396 0.43197854 0.16198641 0.04858206]\n",
            " [0.34604125 0.04319785 0.10799094 0.02429103]\n",
            " [0.15687203 0.51837425 0.21148226 0.11173873]\n",
            " [0.25837746 0.17279142 0.24747924 0.32549978]\n",
            " [0.4152495  0.15119249 0.30147471 0.40808927]\n",
            " [0.276833   0.25054755 0.33297207 0.36436542]\n",
            " [0.32297183 0.19871013 0.38696754 0.47610415]\n",
            " [0.36911066 0.09503528 0.44096302 0.22347746]\n",
            " [0.04613883 0.38878069 0.1799849  0.07287308]]\n",
            "\n",
            "Step 3\n",
            " [[0.05813493 0.01295936 0.0404966  0.05829847]\n",
            " [0.12457485 0.03455828 0.03329721 0.02914923]\n",
            " [0.17717312 0.0302385  0.00539955 0.0874477 ]\n",
            " [0.23807638 0.04319785 0.01619864 0.00971641]\n",
            " [0.20762475 0.00431979 0.01079909 0.00485821]\n",
            " [0.09412322 0.05183742 0.02114823 0.02234775]\n",
            " [0.15502648 0.01727914 0.02474792 0.06509996]\n",
            " [0.2491497  0.01511925 0.03014747 0.08161785]\n",
            " [0.1660998  0.02505476 0.03329721 0.07287308]\n",
            " [0.1937831  0.01987101 0.03869675 0.09522083]\n",
            " [0.2214664  0.00950353 0.0440963  0.04469549]\n",
            " [0.0276833  0.03887807 0.01799849 0.01457462]]\n",
            "\n",
            "Step 4\n",
            " [0.2491497  0.05183742 0.0440963  0.09522083] [0.0276833  0.00431979 0.00539955 0.00485821]\n",
            "\n",
            "Step 5\n",
            " [0.19842975 0.14247645 0.08488228 0.09103047 0.11513625 0.17283029\n",
            " 0.10646634 0.04156724 0.09072287 0.0641597  0.07149359 0.2374873 ] [0.07134149 0.10803089 0.17274261 0.21428246 0.18002244 0.08500643\n",
            " 0.14278536 0.23594172 0.15809291 0.19262682 0.20165121 0.03804493]\n",
            "\n",
            "Step 6\n",
            " [0.73554818 0.5687516  0.32948013 0.29815464 0.39008253 0.67030905\n",
            " 0.4271439  0.14978701 0.36461863 0.24985618 0.26174246 0.86192202]\n",
            "\n",
            "Visualization graph:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}