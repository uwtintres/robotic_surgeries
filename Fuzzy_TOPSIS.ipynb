{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuzzy TOPSIS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIiKz2PSl9wNyXzfiSYtWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwtintres/robotic_surgeries/blob/main/Fuzzy_TOPSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngFXV7lQNt70"
      },
      "source": [
        "This notebook is used for the Fuzzy TOPSIS implementation. The main idea is to firstly rate the attributes for each alternative by the following scale: \n",
        "1.   Very Low (1, 1, 3)\n",
        "2.   Low (1, 3, 5)\n",
        "3. Average (3, 5, 7)\n",
        "4. High (5, 7, 9)\n",
        "5. Very High (7, 9, 9)\n",
        "\n",
        "And the numbers in the brackets represent the Fuzzy Numbers. There could be several deceision makers, in our use case, several surgeons could rate the attributes by the scale and the average of their ratings will be used. \n",
        "As for how it will be calculated, the word representation of the rating is substituted with the appropriate fuzzy numbers from the brackets. Then, as there will be several decicison matrices (if there are several decision makers - doctors), therefore, to build a combined decision matrix the average will be calculated according to the following logic: x = (a, b, c), where a, b, and c are fuzzy numbers in the brackets; a = is the minimum of all a's from all decision matrices; b = the mean of all b componenets; c = maximum of all c components. \n",
        "\n",
        "Now, a combined decision matrix is built and the weights are going to be generated by the same logic - the rating will be provided for each attribute in general and then be substituted by the fuzzy numbers.\n",
        "\n",
        "Next, the benefit/cost criterias are calculated. The benefit criteria: r = (a/c*, b/c*, c/c*), where c* is the maximum of all the c components for the given attribute. And for the cost criteria: r = (a*/c, a*/b, a*/a), where a* is the minimum of all the a components for the given attribute. \n",
        "\n",
        "Next, the weighted normalized fuzzy decision matrix is calculated, where a * a_w, b * b_w, c * c_w and a_w, b_w, c_w are the components of the weight for the current attribute. \n",
        "\n",
        "Compute the Fuzzy Positive Ideal Solution (FPIS) and Fuzzy Negative Ideal Solution (FNIS). For FPIS, labeled as A*, the value is the maximum from all the c components within the attribute, if c components are equal, then the values are compared by the b component. As for the FNIS, labeled as A-, the value is the minimum from all a components within the attribute. \n",
        "\n",
        "Next, we calculate the distance from all the matrix cell values to the A* and A- values by the formula *sqrt(1/3 * [(a1-a2)^2 + (b1-b2)^2 + (c1-c2)^2])*. And this distance value is then used to calculate the closeness coefficient (CCi) = d-/(d- + d*).\n",
        "\n",
        "The rank is then generated according to the closeness coefficient, the highest will get higher rank.\n",
        "\n",
        "\n",
        "The calculation of the ranks is started by uploading the .xslx document with the table of attributes-alternatives' rating, according to the scale above (Very Low - Very High), including the rating of weights. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hy16FxSfmKt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "\n",
        "class FuzzyTopsis():\n",
        "    evaluation_matrix = np.array([])  # Matrix\n",
        "    weighted_normalized = np.array([])  # Weight matrix\n",
        "    normalized_decision = np.array([])  # Normalisation matrix\n",
        "    fuzzy_matrix = np.array([]) # Fuzzy matrix\n",
        "    fuzzy_weights = np.array([])\n",
        "    M = 0  # Number of rows\n",
        "    N = 0  # Number of columns\n",
        "\n",
        "    definitions_matrix = {'very low': [1, 1, 3],\n",
        "                   'low': [1, 3, 5],\n",
        "                   'average': [3, 5, 7],\n",
        "                   'high': [5, 7, 9],\n",
        "                   'very high': [7, 9, 9]}\n",
        "                   \n",
        "    definitions_weights = {'very low': [1, 1, 3],\n",
        "                  'low': [1, 3, 5],\n",
        "                  'average': [3, 5, 7],\n",
        "                  'high': [5, 7, 9],\n",
        "                  'very high': [7, 9, 9]}\n",
        "\n",
        "    '''\n",
        "\tCreate an evaluation matrix consisting of m alternatives and n attributes.\n",
        "\t  '''\n",
        "\n",
        "    def __init__(self, evaluation_matrix, weight_matrix, criteria):\n",
        "\n",
        "      # MÃ—N matrix\n",
        "      self.evaluation_matrix = np.array(evaluation_matrix, dtype=\"object\")\n",
        "\n",
        "      # M alternatives (options)\n",
        "      self.row_size = len(self.evaluation_matrix)\n",
        "\n",
        "      # N attributes/criteria\n",
        "      self.column_size = len(self.evaluation_matrix[0])\n",
        "\n",
        "      # N size weight matrix\n",
        "      self.weight_matrix = np.array(weight_matrix, dtype=\"object\")\n",
        "      #self.weight_matrix = self.weight_matrix/sum(self.weight_matrix)\n",
        "      self.criteria = np.array(criteria, dtype=\"object\")\n",
        "    '''\n",
        "\t# Step 2\n",
        "\tThe word representation of ratings converted to fuzzy numbers\n",
        "\t'''\n",
        "    def step_2(self):\n",
        "        self.fuzzy_matrix = np.empty(shape=(self.row_size,self.column_size),dtype=\"object\")\n",
        "        self.fuzzy_weights = np.empty(shape=(self.column_size),dtype=\"object\")\n",
        "        #self.fuzzy_matrix = np.copy(self.evaluation_matrix)\n",
        "        # Substituting words with fuzzy numbers for fuzzy matrix\n",
        "        for i in range(self.row_size):\n",
        "          for j in range(self.column_size):\n",
        "            if self.evaluation_matrix[i,j].lower() in self.definitions_matrix:\n",
        "              self.fuzzy_matrix[i,j] = self.definitions_matrix[self.evaluation_matrix[i,j].lower()]\n",
        "            else:\n",
        "              print(\"Wrong rating for cell [\", i, j, \"]\")\n",
        "        # Substituting words with fuzzy numbers for fuzzy weights\n",
        "        for i in range(len(self.weight_matrix)):\n",
        "          if self.weight_matrix[i].lower() in self.definitions_weights:\n",
        "              self.fuzzy_weights[i] = self.definitions_weights[self.weight_matrix[i].lower()]\n",
        "          else:\n",
        "              print(\"Wrong rating for cell [\", i, j, \"]\")\n",
        "        print(\"Fuzzy matrix: \", self.fuzzy_matrix)\n",
        "        print(\"\\nFuzzy weights: \", self.fuzzy_weights)\n",
        "    '''\n",
        "  # Step 3\n",
        "  Compute normalized fuzzy decision matrix\n",
        "  '''\n",
        "    def step_3(self):\n",
        "        # normalized scores\n",
        "        self.normalized_decision = copy.deepcopy(self.fuzzy_matrix)\n",
        "        for j in range(self.column_size):\n",
        "          for i in range(self.row_size):\n",
        "              # finding benefit and cost criterias for each attribute\n",
        "              benefit_criteria = max(x[2] for x in self.fuzzy_matrix[:, j]) # max better\n",
        "              cost_criteria = min(x[0] for x in self.fuzzy_matrix[:, j]) # min better\n",
        "              \n",
        "              # calculating normalized matrix according to criteria\n",
        "              if self.criteria[j]:\n",
        "                for k in range(3):\n",
        "                  self.normalized_decision[i,j][k] = self.fuzzy_matrix[i,j][k] / benefit_criteria\n",
        "                #print(\"benefit criteria\", benefit_criteria)\n",
        "              else:\n",
        "                for k in range(3):\n",
        "                  self.normalized_decision[i,j][k] = cost_criteria / self.fuzzy_matrix[i,j][-(k+1)] \n",
        "                #print(\"row\", i, \"col\", j)\n",
        "                #print(\"cost criteria\", cost_criteria)\n",
        "                #print(\"fuzzy value\", self.fuzzy_matrix[i,j])\n",
        "                #print(\"normalized value\", self.normalized_decision[i,j])\n",
        "\n",
        "        print(\"\\nNormalized decision matrix: \", self.normalized_decision)\n",
        "\n",
        "    '''\n",
        "\t# Step 4\n",
        "\tCalculate the weighted normalised decision matrix\n",
        "\t'''\n",
        "\n",
        "    def step_4(self):\n",
        "        self.weighted_normalized = copy.deepcopy(self.normalized_decision)\n",
        "        for i in range(self.row_size):\n",
        "            for j in range(self.column_size):\n",
        "              value = [1, 1, 1]\n",
        "              for k in range(3):\n",
        "                value[k] = self.normalized_decision[i,j][k] * self.fuzzy_weights[j][k]\n",
        "                #print(\"value\", value, \"normalized\", self.normalized_decision[i,j][k],\" weight\", self.fuzzy_weights[j][k])\n",
        "\n",
        "              self.weighted_normalized[i, j] = value  \n",
        "        print(\"\\nStep 4\")\n",
        "        print(\"\\nWeighted Normalization matrix:\",  self.weighted_normalized)\n",
        "\n",
        "    '''\n",
        "\t# Step 5\n",
        "\tDetermine the ideal worst alternative and the ideal best alternative:\n",
        "\t'''\n",
        "\n",
        "    def step_5(self):\n",
        "        self.worst_alternatives = np.zeros(self.column_size, dtype=\"object\")\n",
        "        self.best_alternatives = np.zeros(self.column_size, dtype=\"object\")\n",
        "        self.weighted_normalized_copy = copy.deepcopy(self.weighted_normalized)\n",
        "        for j in range(self.column_size):\n",
        "          max_best = []\n",
        "          min_worst = []\n",
        "          for i in range(self.row_size):\n",
        "            #print(\"max best\", max_best)\n",
        "            self.weighted_normalized_copy[i,j].reverse()\n",
        "            #print(\"reversed\",self.weighted_normalized_copy[i,j])\n",
        "            heapq.heappush(max_best, tuple(np.negative(self.weighted_normalized_copy[i, j])))\n",
        "            heapq.heappush(min_worst, self.weighted_normalized[i,j])\n",
        "          best = list(heapq.heappop(max_best))\n",
        "          best.reverse()\n",
        "          self.best_alternatives[j] = np.negative(best)\n",
        "          self.worst_alternatives[j] = heapq.heappop(min_worst)\n",
        "        print(\"\\nStep 5\")\n",
        "        print(\"\\nA*:\", self.best_alternatives)\n",
        "        print(\"\\nA-:\", self.worst_alternatives)   \n",
        "    '''\n",
        "\t# Step 6\n",
        "\tCalculate the L2-distance between the target alternative with the ideal worst \n",
        "  value and the ideal best value.\n",
        "\t'''\n",
        "\n",
        "    def step_6(self):\n",
        "        self.worst_distance = np.zeros(self.row_size)\n",
        "        self.best_distance = np.zeros(self.row_size)\n",
        "\n",
        "        self.worst_distance_mat = copy.deepcopy(self.weighted_normalized)\n",
        "        self.best_distance_mat = copy.deepcopy(self.weighted_normalized)\n",
        "\n",
        "        for i in range(self.row_size):\n",
        "          for j in range(self.column_size):\n",
        "            current_worst_distance = 0\n",
        "            current_best_distance = 0\n",
        "            for k in range(3):\n",
        "              current_worst_distance += (self.weighted_normalized[i,j][k]-self.worst_alternatives[j][k])**2\n",
        "              current_best_distance += (self.weighted_normalized[i,j][k]-self.best_alternatives[j][k])**2\n",
        "            self.worst_distance_mat[i, j] = (current_worst_distance / 3)**0.5\n",
        "            self.best_distance_mat[i, j] = (current_best_distance / 3)**0.5\n",
        "            \n",
        "            self.worst_distance[i] += self.worst_distance_mat[i,j]\n",
        "            self.best_distance[i] += self.best_distance_mat[i,j]\n",
        "        print(\"\\nStep 6\")\n",
        "        print(\"\\nbest matrix\", self.best_distance_mat)\n",
        "        print(\"\\nworst matrix\", self.worst_distance_mat)\n",
        "        print(\"\\nd*:\", self.best_distance)\n",
        "        print(\"\\nd-:\", self.worst_distance)\n",
        "    '''\n",
        "\t# Step 7\n",
        "\tCalculate the closeness coefficient\n",
        "\t'''\n",
        "\n",
        "    def step_7(self):\n",
        "        np.seterr(all='ignore')\n",
        "        self.closeness_coefficient = np.zeros(self.row_size)\n",
        "\n",
        "        for i in range(self.row_size):\n",
        "            self.closeness_coefficient[i] = self.worst_distance[i] / \\\n",
        "                (self.worst_distance[i]+self.best_distance[i])\n",
        "    \n",
        "    def ranking(self, data):\n",
        "        return [i+1 for i in np.argsort(-1*data)]\n",
        "    '''\n",
        "  # Step 8\n",
        "  Calculate and visualize the ranking\n",
        "  '''\n",
        "    def rank_to_closeness_coefficient(self):\n",
        "        return self.ranking(self.closeness_coefficient)\n",
        "\n",
        "    def visualization(self, ranking):\n",
        "        #ax = fig.add_axes([0,0,1,1])\n",
        "        axes = []\n",
        "        for i, rank in enumerate(ranking):\n",
        "          axes.append(((rank), (i + 1)))\n",
        "        axes.sort(key=lambda x: x[0])\n",
        "        x_axis,y_axis = ['A' + str(val[0]) for val in axes],[val[1] for val in axes]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        ax = pd.Series(y_axis).plot(kind='bar')\n",
        "        ax.set_xticklabels(x_axis)\n",
        "\n",
        "        rects = ax.patches\n",
        "        for rect, label in zip(rects, y_axis):\n",
        "            height = rect.get_height()\n",
        "            ax.text(rect.get_x() + rect.get_width()/2, height, label, ha='center', va='bottom')\n",
        "        ax.bar(x_axis,y_axis)\n",
        "\n",
        "    def calc(self):\n",
        "        print(\"Step 1\\n\", self.evaluation_matrix, end=\"\\n\\n\")\n",
        "        self.step_2()\n",
        "        #print(\"Step 2\\n\", self.normalized_decision, end=\"\\n\\n\")\n",
        "        self.step_3()\n",
        "        #print(\"Step 3\\n\", self.weighted_normalized, end=\"\\n\\n\")\n",
        "        self.step_4()\n",
        "        self.step_5()\n",
        "        self.step_6()\n",
        "        self.step_7()\n",
        "        print(\"Step 7\\n\", self.closeness_coefficient, end=\"\\n\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qmaJ2fkwyIt"
      },
      "source": [
        "The driver code for testing is presented below. The execution plan is as follows:\n",
        "  1. Read the excel file, where the file name and sheet_name should be provided to specify which case user wants to test. \n",
        "  2. Read the excel file to store the weights and criteria values.\n",
        "  3. Create Fuzzy Topsis instance with the read values\n",
        "  4. Calculate the rankings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jfM_it3Gfpx",
        "outputId": "a5f1a68f-6ca0-4300-cd8f-5c033b072a80"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "xl = pd.read_excel(\"Fuzzy TOPSIS with custom weights.xlsx\", sheet_name=\"Beginning\")\n",
        "xl = pd.read_excel(\"Fuzzy TOPSIS with custom weights.xlsx\", sheet_name=\"Beginning\", \n",
        "                   usecols=range(1, len(xl.columns)+1))\n",
        "\n",
        "# initializing input matrix, weights, criterias\n",
        "input_matrix = xl.tail(n=len(xl.index) - 2).values.tolist()\n",
        "weights = xl.loc[0].values\n",
        "criterias = xl.head(n=0).columns.values\n",
        "new_criterias = []\n",
        "for criteria in criterias:\n",
        "  # if the attribute is non beneficiary, meaning min value is better -> False, \n",
        "  # otherwise, the criteria is True\n",
        "  new_criterias.append(False if criteria[0] == 'N' else True)\n",
        "print('input matrix: ', input_matrix)\n",
        "print('weights: ', weights)\n",
        "print('criterias: ', new_criterias)\n",
        "# creating Topsis instance with the values above\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input matrix:  [['very high', 'high', 'high', 'very high'], ['high', 'average', 'very high', 'low'], ['high', 'very low', 'high', 'average'], ['average', 'high', 'low', 'very high'], ['very high', 'high', 'very low', 'low'], ['average', 'average', 'very low', 'very low'], ['very low', 'average', 'high', 'average'], ['very high', 'low', 'average', 'very low'], ['low', 'low', 'average', 'average'], ['high', 'very low', 'very low', 'high'], ['average', 'very high', 'low', 'low'], ['very low', 'very high', 'very low', 'very low']]\n",
            "weights:  ['high' 'low' 'very low' 'very low']\n",
            "criterias:  [False, False, False, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AOqYfG3HHbKn",
        "outputId": "085e766d-f6b2-4384-a1fb-82d0392f6b87"
      },
      "source": [
        "t = FuzzyTopsis(input_matrix, weights, new_criterias)\n",
        "\n",
        "# calculating the ranking\n",
        "t.calc()\n",
        "\n",
        "ranks = t.rank_to_closeness_coefficient()\n",
        "\n",
        "print(\"Visualization graph:\")\n",
        "t.visualization(ranks)  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            " [['very high' 'high' 'high' 'very high']\n",
            " ['high' 'average' 'very high' 'low']\n",
            " ['high' 'very low' 'high' 'average']\n",
            " ['average' 'high' 'low' 'very high']\n",
            " ['very high' 'high' 'very low' 'low']\n",
            " ['average' 'average' 'very low' 'very low']\n",
            " ['very low' 'average' 'high' 'average']\n",
            " ['very high' 'low' 'average' 'very low']\n",
            " ['low' 'low' 'average' 'average']\n",
            " ['high' 'very low' 'very low' 'high']\n",
            " ['average' 'very high' 'low' 'low']\n",
            " ['very low' 'very high' 'very low' 'very low']]\n",
            "\n",
            "Fuzzy matrix:  [[list([7, 9, 9]) list([5, 7, 9]) list([5, 7, 9]) list([7, 9, 9])]\n",
            " [list([5, 7, 9]) list([3, 5, 7]) list([7, 9, 9]) list([1, 3, 5])]\n",
            " [list([5, 7, 9]) list([1, 1, 3]) list([5, 7, 9]) list([3, 5, 7])]\n",
            " [list([3, 5, 7]) list([5, 7, 9]) list([1, 3, 5]) list([7, 9, 9])]\n",
            " [list([7, 9, 9]) list([5, 7, 9]) list([1, 1, 3]) list([1, 3, 5])]\n",
            " [list([3, 5, 7]) list([3, 5, 7]) list([1, 1, 3]) list([1, 1, 3])]\n",
            " [list([1, 1, 3]) list([3, 5, 7]) list([5, 7, 9]) list([3, 5, 7])]\n",
            " [list([7, 9, 9]) list([1, 3, 5]) list([3, 5, 7]) list([1, 1, 3])]\n",
            " [list([1, 3, 5]) list([1, 3, 5]) list([3, 5, 7]) list([3, 5, 7])]\n",
            " [list([5, 7, 9]) list([1, 1, 3]) list([1, 1, 3]) list([5, 7, 9])]\n",
            " [list([3, 5, 7]) list([7, 9, 9]) list([1, 3, 5]) list([1, 3, 5])]\n",
            " [list([1, 1, 3]) list([7, 9, 9]) list([1, 1, 3]) list([1, 1, 3])]]\n",
            "\n",
            "Fuzzy weights:  [list([5, 7, 9]) list([1, 3, 5]) list([1, 1, 3]) list([1, 1, 3])]\n",
            "\n",
            "Normalized decision matrix:  [[list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.7777777777777778, 1.0, 1.0])]\n",
            " [list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])]\n",
            " [list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])]\n",
            " [list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])\n",
            "  list([0.7777777777777778, 1.0, 1.0])]\n",
            " [list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])]\n",
            " [list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])]\n",
            " [list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])]\n",
            " [list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])]\n",
            " [list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])]\n",
            " [list([0.5555555555555556, 0.7777777777777778, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 1.0])]\n",
            " [list([0.3333333333333333, 0.5555555555555556, 0.7777777777777778])\n",
            "  list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 0.5555555555555556])]\n",
            " [list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.7777777777777778, 1.0, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 0.3333333333333333])]]\n",
            "\n",
            "Step 4\n",
            "\n",
            "Weighted Normalization matrix: [[list([3.888888888888889, 7.0, 9.0])\n",
            "  list([0.5555555555555556, 2.3333333333333335, 5.0])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 3.0])\n",
            "  list([0.7777777777777778, 1.0, 3.0])]\n",
            " [list([2.7777777777777777, 5.444444444444445, 9.0])\n",
            "  list([0.3333333333333333, 1.6666666666666667, 3.888888888888889])\n",
            "  list([0.7777777777777778, 1.0, 3.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666667])]\n",
            " [list([2.7777777777777777, 5.444444444444445, 9.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666665])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 3.0])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 2.3333333333333335])]\n",
            " [list([1.6666666666666665, 3.8888888888888893, 7.0])\n",
            "  list([0.5555555555555556, 2.3333333333333335, 5.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666667])\n",
            "  list([0.7777777777777778, 1.0, 3.0])]\n",
            " [list([3.888888888888889, 7.0, 9.0])\n",
            "  list([0.5555555555555556, 2.3333333333333335, 5.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666667])]\n",
            " [list([1.6666666666666665, 3.8888888888888893, 7.0])\n",
            "  list([0.3333333333333333, 1.6666666666666667, 3.888888888888889])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])]\n",
            " [list([0.5555555555555556, 0.7777777777777777, 3.0])\n",
            "  list([0.3333333333333333, 1.6666666666666667, 3.888888888888889])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 3.0])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 2.3333333333333335])]\n",
            " [list([3.888888888888889, 7.0, 9.0])\n",
            "  list([0.1111111111111111, 1.0, 2.7777777777777777])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 2.3333333333333335])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])]\n",
            " [list([0.5555555555555556, 2.333333333333333, 5.0])\n",
            "  list([0.1111111111111111, 1.0, 2.7777777777777777])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 2.3333333333333335])\n",
            "  list([0.3333333333333333, 0.5555555555555556, 2.3333333333333335])]\n",
            " [list([2.7777777777777777, 5.444444444444445, 9.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666665])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])\n",
            "  list([0.5555555555555556, 0.7777777777777778, 3.0])]\n",
            " [list([1.6666666666666665, 3.8888888888888893, 7.0])\n",
            "  list([0.7777777777777778, 3.0, 5.0])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666667])\n",
            "  list([0.1111111111111111, 0.3333333333333333, 1.6666666666666667])]\n",
            " [list([0.5555555555555556, 0.7777777777777777, 3.0])\n",
            "  list([0.7777777777777778, 3.0, 5.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])\n",
            "  list([0.1111111111111111, 0.1111111111111111, 1.0])]]\n",
            "\n",
            "Step 5\n",
            "\n",
            "A*: [array([3.88888889, 7.        , 9.        ])\n",
            " array([0.77777778, 3.        , 5.        ])\n",
            " array([0.77777778, 1.        , 3.        ])\n",
            " array([0.77777778, 1.        , 3.        ])]\n",
            "\n",
            "A-: [list([0.5555555555555556, 0.7777777777777777, 3.0])\n",
            " list([0.1111111111111111, 0.3333333333333333, 1.6666666666666665])\n",
            " list([0.1111111111111111, 0.1111111111111111, 1.0])\n",
            " list([0.1111111111111111, 0.1111111111111111, 1.0])]\n",
            "\n",
            "Step 6\n",
            "\n",
            "best matrix [[0.0 0.4057204129667896 0.18144368465060579 0.0]\n",
            " [1.103678846351951 1.034388151390292 0.0 0.9428090415820634]\n",
            " [1.103678846351951 2.494438257849294 0.18144368465060579\n",
            "  0.5289946984105813]\n",
            " [2.4911365512296646 0.4057204129667896 0.9428090415820634 0.0]\n",
            " [0.0 0.4057204129667896 1.320929962972371 0.9428090415820634]\n",
            " [2.4911365512296646 1.034388151390292 1.320929962972371\n",
            "  1.320929962972371]\n",
            " [5.348743169936503 1.034388151390292 0.18144368465060579\n",
            "  0.5289946984105813]\n",
            " [0.0 1.7684942794538256 0.5289946984105813 1.320929962972371]\n",
            " [4.036867138796656 1.7684942794538256 0.5289946984105813\n",
            "  0.5289946984105813]\n",
            " [1.103678846351951 2.494438257849294 1.320929962972371\n",
            "  0.18144368465060579]\n",
            " [2.4911365512296646 0.0 0.9428090415820634 0.9428090415820634]\n",
            " [5.348743169936503 0.0 1.320929962972371 1.320929962972371]]\n",
            "\n",
            "worst matrix [[5.348743169936503 2.2589556565891713 1.243915231388642\n",
            "  1.320929962972371]\n",
            " [4.572236848003249 1.5017136987195032 1.320929962972371\n",
            "  0.40572041296678973]\n",
            " [4.572236848003249 0.0 1.243915231388642 0.8215212226969939]\n",
            " [2.995195054689738 2.2589556565891713 0.40572041296678973\n",
            "  1.320929962972371]\n",
            " [5.348743169936503 2.2589556565891713 0.0 0.40572041296678973]\n",
            " [2.995195054689738 1.5017136987195032 0.0 0.0]\n",
            " [0.0 1.5017136987195032 1.243915231388642 0.8215212226969939]\n",
            " [5.348743169936503 0.7481114769157096 0.8215212226969939 0.0]\n",
            " [1.462845752454185 0.7481114769157096 0.8215212226969939\n",
            "  0.8215212226969939]\n",
            " [4.572236848003249 0.0 0.0 1.243915231388642]\n",
            " [2.995195054689738 2.494438257849294 0.40572041296678973\n",
            "  0.40572041296678973]\n",
            " [0.0 2.494438257849294 0.0 0.0]]\n",
            "\n",
            "d*: [0.5871641  3.08087604 4.30855549 3.83966601 2.66945942 6.16738463\n",
            " 7.0935697  3.61841894 6.86335082 5.10049075 4.37675463 7.9906031 ]\n",
            "\n",
            "d-: [10.17254402  7.80060092  6.6376733   6.98080109  8.01341924  4.49690875\n",
            "  3.56715015  6.91837587  3.85399967  5.81615208  6.30107414  2.49443826]\n",
            "Step 7\n",
            " [0.94542937 0.71686968 0.60638905 0.64514785 0.75011797 0.42167902\n",
            " 0.33460687 0.65659207 0.35960377 0.53277845 0.59010818 0.23790447]\n",
            "\n",
            "Visualization graph:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}