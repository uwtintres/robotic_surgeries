{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuzzy Flask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x9z4gSXfPSQvD3BKnagLQNwzfI5K345q",
      "authorship_tag": "ABX9TyNBlx3Vh4dxDtU/zaqjLENq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwtintres/robotic_surgeries/blob/main/Fuzzy_Flask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project is the work of Alina Saduova, CSS graduate student at UWT, Spring'21.\n",
        "\n",
        "This notebook illustrates the implementation of the frontend Flask web application for the whole testing and simulation.\n",
        "\n",
        "Firstle, we start with accessing the path of the colab notebooks in the Google Drive in order to be able to call all the notebooks that take part in the simulation. You may change the path to yours.\n"
      ],
      "metadata": {
        "id": "68gL0U2p2HuE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxJ8BwkwyDmj",
        "outputId": "525f7484-866b-4125-f80c-d8d5cf5c5363"
      },
      "source": [
        "path_to_col = /content/drive/MyDrive/Colab Notebooks/\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Later, it is important to download all the requirements we need to launch flask app."
      ],
      "metadata": {
        "id": "xULeSJbk2vuL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeLhgFaeyKL9"
      },
      "source": [
        "!pip install flask\n",
        "!pip install flask-ngrok\n",
        "!pip install import-ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if we are in the right directory before launching."
      ],
      "metadata": {
        "id": "R3gAeTBQ23sU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JeKH1euYyos-",
        "outputId": "ebfa48ea-9429-4bd6-ae6a-e51a22bf75c7"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, calling the main code to create a Flask web app that is taking the weights from the user on the web app, calls to all of the methods: TOPSIS, PROMETHEE II, TOPSIS with AHP, Fuzzy TOPSIS to showcase the rankings."
      ],
      "metadata": {
        "id": "EUa_6eTW2-N6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLjc8ErythR"
      },
      "source": [
        "import pandas as pd\n",
        "import import_ipynb\n",
        "import Fuzzy as fz\n",
        "import TOPSIS as tp\n",
        "import AHP as ahp\n",
        "import Promethee as prm\n",
        "import numpy as np\n",
        "import itertools\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randrange\n",
        "from flask import Flask, render_template, redirect, url_for, request, make_response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import datetime\n",
        "\n",
        "# defining the template folder for html template, static folder for the graphs\n",
        "app = Flask(__name__, template_folder=path_to_col + '/FuzzyCode/templates', static_folder=path_to_col+'/FuzzyCode/static')\n",
        "# running the web by creating tunnel and generating url via ngrok\n",
        "run_with_ngrok(app)\n",
        "\n",
        "#Renders template as soon as the application runs\n",
        "@app.route('/')\n",
        "def hello_world():\n",
        "    return render_template('demo1.html')\n",
        "\n",
        "# REST API to get the best alternative\n",
        "@app.route('/bestsmp11', methods=['POST'])\n",
        "def login():\n",
        "\tdatafromjs = request.form['mydata']\n",
        "\tres = callMethods(datafromjs)\n",
        "\tprint(\"res\", res)\n",
        "\n",
        "\t#Creating Response to send\n",
        "\tresp = make_response(res)\n",
        "\tresp.headers['Content-Type'] = \"application/json\"\n",
        "\treturn resp\n",
        "\n",
        "# This function creates the 3D graphs and stores in the static folder\n",
        "def createGraph(perf_score, vars1, vars2, sh_n):\n",
        "  x = vars1\n",
        "  y = vars2\n",
        "  z = perf_score\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(16, 12)\n",
        "  ax = plt.axes(projection='3d')\n",
        "  ax.scatter(x, y, z,\n",
        "              linewidths=1, alpha=.7,\n",
        "              edgecolor='k',\n",
        "              s=200,\n",
        "              c=z)\n",
        "  # the lables of the graph change depending on the input sheet\n",
        "  if sh_n == 1:\n",
        "    ax.set_xlabel('Risk of cancer')\n",
        "    ax.set_ylabel('Blood loss')\n",
        "  elif sh_n == 2:\n",
        "    ax.set_xlabel('Distance to portal vein')\n",
        "    ax.set_ylabel('Imaging')\n",
        "  else:\n",
        "    ax.set_xlabel('Amount of mucosa')\n",
        "    ax.set_ylabel('Bleeding rate')\n",
        "  ax.set_zlabel('TOPSIS Performance Score')\n",
        "\n",
        "  # Path of location to store graph\n",
        "  name = '/static/graph_very_new'+datetime.datetime.now().strftime(\"%s\")+'.png'\n",
        "  fig.savefig(path_to_col+'/FuzzyCode'+name)\n",
        "  return name\n",
        "\n",
        "# This function executes all methods and returns the top 5 alternatives\n",
        "def callMethods(datafromjs):\n",
        "  d = datafromjs.split(\",\")\t\n",
        "  w = [float(d[0]), float(d[1]), float(d[2]), float(d[3])]\n",
        "  print('weights w', w)\n",
        "\n",
        "  # calculating TOPSIS results\n",
        "  t = tp.Topsis(input_matrices[d[5]], w, new_criterias_list[d[5]])\n",
        "  t.calc()\n",
        "  topsis_ranks = t.rank_to_preformance_score()\n",
        "  topsis_p_s = t.get_perf_score()\n",
        "\n",
        "  # calculating AHP results and using them for TOPSIS\n",
        "  t_ahp = tp.Topsis(input_matrices[d[5]], ahp_weights[d[4]], new_criterias_list[d[5]])\n",
        "  t_ahp.calc()\n",
        "  topsis_ahp_ranks = t_ahp.rank_to_preformance_score()\n",
        "  topsis_ahp_p_s = t_ahp.get_perf_score()\n",
        "  \n",
        "  # calculating PROMETHEE results\n",
        "  p = prm.Promethee(input_matrices[d[5]], w, new_criterias_list[d[5]])\n",
        "  p.calc()\n",
        "  promethee_ranks = p.rank_to_preformance_score()\n",
        "  promethee_p_s = p.get_perf_score()\n",
        "\n",
        "  # calculating Fuzzy TOPSIS results\n",
        "  fuzzy_weights = getFuzzyWeights(w)\n",
        "  f = fz.FuzzyTopsis(fuzzy_matrices[d[5]], fuzzy_weights, new_criterias_list[d[5]])\n",
        "  f.calc()\n",
        "  fuzzy_ranks = f.rank_to_closeness_coefficient()\n",
        "  fuzzy_p_s = f.get_closeness_coefficient()\n",
        "\n",
        "  # Appending 5 best results\n",
        "  best_df = np.empty(shape=((len(input_matrices[d[5]]) + 4), (len(input_matrices[d[5]][0]) + 4)))\n",
        "  for i in range(5):\n",
        "    row = itertools.chain(t.normalized_decision[topsis_ranks[i] - 1],\\\n",
        "                          [topsis_p_s[topsis_ranks[i] - 1]],[topsis_ahp_p_s[topsis_ranks[i]-1]],\\\n",
        "                          [promethee_p_s[topsis_ranks[i]-1]],[fuzzy_p_s[topsis_ranks[i]-1]])\n",
        "    best_df[i] = list(row)\n",
        "\n",
        "  s = \"\"\n",
        "  for row in best_df:\n",
        "    for e in row:\n",
        "      s += str(e)+\" \"\n",
        "    s += \",\"\n",
        "  \n",
        "  # Calculating correlation coefficients\n",
        "  correlation = []\n",
        "  correlation.append(np.corrcoef(topsis_ranks, topsis_ahp_ranks)[0, 1])\n",
        "  correlation.append(np.corrcoef(topsis_ranks, promethee_ranks)[0, 1])\n",
        "  correlation.append(np.corrcoef(topsis_ahp_ranks, promethee_ranks)[0, 1])\n",
        "  correlation.append(np.corrcoef(topsis_ahp_ranks, fuzzy_ranks)[0, 1])\n",
        "  correlation.append(np.corrcoef(promethee_ranks, fuzzy_ranks)[0, 1])\n",
        "  correlation.append(np.corrcoef(topsis_ranks, fuzzy_ranks)[0, 1])\n",
        "  for el in correlation:\n",
        "    s += str(el) + \" \"\n",
        "  s += \",\"\n",
        "\n",
        "  # providing the x and y axes information depending on the input sheet\n",
        "  if (d[5] == 'Beginning'):\n",
        "    attribute1 = t.normalized_decision[:, 0]\n",
        "    attribute2 = t.normalized_decision[:, 1]\n",
        "    sh_number = 1\n",
        "  elif (d[5] == 'Middle'):\n",
        "    attribute1 = t.normalized_decision[:, 1]\n",
        "    attribute2 = t.normalized_decision[:, 3]\n",
        "    sh_number = 2\n",
        "  else:\n",
        "    attribute1 = t.normalized_decision[:, 1]\n",
        "    attribute2 = t.normalized_decision[:, 2]\n",
        "    sh_number = 3\n",
        "\n",
        "  name = createGraph(topsis_p_s, attribute1, attribute2, sh_number)\n",
        "  s += name\n",
        "\n",
        "  return s\n",
        "\n",
        "# this method calls AHP to get the correlation of the attributes and to generate weights\n",
        "def getAhpWeights(ahp_filename, ahp_sheetnames=[0]):\n",
        "  weights_list = {}\n",
        "  t = ahp.AHP()\n",
        "  for ahp_sheetname in ahp_sheetnames:\n",
        "    xl = pd.read_excel(ahp_filename, sheet_name=ahp_sheetname)\n",
        "    xl = pd.read_excel(ahp_filename, sheet_name=ahp_sheetname, \n",
        "                    usecols=range(1, len(xl.columns)+1))\n",
        "    ahp_input_matrix = xl.values.tolist()\n",
        "    weights = t.calcAHP(ahp_input_matrix)\n",
        "    weights_list[ahp_sheetname] = weights\n",
        "  return weights_list\n",
        "\n",
        "# this method translates quantitative weights from the web app to qualitative data for Fuzzy TOPSIS\n",
        "def getFuzzyWeights(weights):\n",
        "  for i in range(len(weights)):\n",
        "    if 0 <= weights[i] <= 0.19:\n",
        "      weights[i] = 'very low'\n",
        "    elif 0.2 <= weights[i] <= 0.39:\n",
        "      weights[i] = 'low'\n",
        "    elif 0.4 <= weights[i] <= 0.59:\n",
        "      weights[i] = 'average'\n",
        "    elif 0.6 <= weights[i] <= 0.79:\n",
        "      weights[i] = 'high'\n",
        "    else:\n",
        "      weights[i] = 'very high'\n",
        "  return weights\n",
        "\n",
        "# this method gets the input data depending on the input sheet name\n",
        "def getMatrices(filename, tp_sheetnames):\n",
        "  new_criterias_list = {}\n",
        "  input_matrices = {}\n",
        "\n",
        "  for tp_sheetname in tp_sheetnames:\n",
        "    xl = pd.read_excel(filename, sheet_name=tp_sheetname)\n",
        "    xl = pd.read_excel(filename, sheet_name=tp_sheetname, \n",
        "                        usecols=range(1, len(xl.columns)+1))\n",
        "    \n",
        "    # initializing input matrix, weights, criterias\n",
        "    input_matrix = xl.tail(n=len(xl.index) - 2).values.tolist()\n",
        "    criterias = xl.head(n=0).columns.values\n",
        "    new_criterias = []\n",
        "    for criteria in criterias:\n",
        "      new_criterias.append(False if criteria[0] == 'N' else True)\n",
        "    new_criterias_list[tp_sheetname] = new_criterias\n",
        "    input_matrices[tp_sheetname] = input_matrix\n",
        "\n",
        "  print('input matrices: ', input_matrices)\n",
        "  print('criterias: ', new_criterias_list)\n",
        "  return input_matrices, new_criterias_list\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  # setting the paths for the input files and their sheetnames\n",
        "  topsis_filename = path_to_col+\"/FuzzyCode/TOPSIS with custom weights.xlsx\"\n",
        "  tp_sheetnames = ['Beginning', 'Middle', 'Ending']\n",
        "  input_matrices, new_criterias_list = getMatrices(topsis_filename, tp_sheetnames)\n",
        "  \n",
        "  fuzzy_filename = path_to_col+\"/FuzzyCode/Fuzzy TOPSIS with custom weights.xlsx\"\n",
        "  fuzzy_matrices, fuzzy_criterias = getMatrices(fuzzy_filename, tp_sheetnames)\n",
        "\n",
        "  ahp_importance_filename = path_to_col+\"/FuzzyCode/AHP Importance.xlsx\"\n",
        "  sheetnames = ['Beginning_bl', 'Beginning_rc', 'Beginning_general', 'Middle_dist', 'Middle_vision', 'Ending_muc', 'Ending_br']\n",
        "  ahp_weights = getAhpWeights(ahp_importance_filename, sheetnames)\n",
        "  app.run()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}